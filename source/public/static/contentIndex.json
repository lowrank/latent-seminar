{"2022-Fall/on-Gaussian-Correlation-Inequality":{"title":"on Gaussian Correlation Inequality","links":[],"tags":["math-PR","math-CA","math-CO"],"content":"\n\n                  \n                  Info\n                  \n                \n\nThe Gaussian Correlation Inequality was proved in 2014 (arXiv: 1408.1028). The interesting story can be found in Quanta Magazine.\n\n\nThe inequality is to show the Gaussian measure \\mu on centrally symmetric convex sets A and B satisfies\n\\mu(A\\cap B)\\ge \\mu(A)\\mu(B).\nThat is to say, if a dart hits the wall with standard Gaussian distribution, suppose two targets are centrally symmetric convex sets A,  B, then hitting both targets with one dart is easier than hitting A with the first dart and hitting B with the second, vice versa.\nThe proof of inequality is simple and elegant. I think there are a few keys in the proof which are insightful (that is why this note exists üòÅ).  The first observation is the following.\n\n\n                  \n                  Observation \n                  \n                \n\nA centrally symmetric convex closed set can be formed by the intersection of countable symmetric strips. 1\n\n\nThis observation of ‚Äústrips‚Äù is natural, since a convex symmetric body can be approximated by a sequence of convex, symmetric polytopes. Moreover, convex, symmetric polytopes are just slices of the unit cube in a higher dimension satisfying the constraints \\{|\\langle x, v_i \\rangle |\\le 1\\} for i=1,2,\\cdots, k. Therefore, the problem can be reduced to proving\n\n\n                  \n                  Gaussian Correlation Theorem \n                  \n                \n\n\\mathbb{P}\\left(\\bigcap_{i=1}^n A_i\\right) \\ge \\mathbb{P}\\left(\\bigcap_{i=1}^k A_i\\right) \\mathbb{P}\\left(\\bigcap_{i=k+1}^n A_i\\right),\nwhere A_i = \\{|X_i|\\le x_i\\}, i=1,2,\\cdots, n and (X_1, \\cdots, X_n)\\sim \\mathcal{N}(\\mathbf{0}, \\Sigma_n).\n\n\nThe special case k=1 was proved by the following theorem 2.\n\n\n                  \n                  Theorem (Khatri) \n                  \n                \n\nLet \\{X_i\\}_{1\\le i\\le n} be a jointly Gaussian random variables with mean zero. Then\n\\mathbb{P}(\\max_{1\\le i\\le n} |X_i| \\le 1) \\ge \\mathbb{P}(|X_1|\\le 1)\\, \\mathbb{P}(\\max_{2\\le i \\le n} |X_i| \\le 1).\n\n\nMultivariate Gamma-type distribution\nThe set \\{|X_i|\\le 1\\} is better described by chi-squared distribution or Gamma distribution. Surprisingly, the multivariate Gamma distributions on \\mathbb{R}^n have several (non-equivalent) definitionsü§£.\nThe \\Gamma(\\alpha, R) distribution is defined as follows.\n\n\n                  \n                  Definition \n                  \n                \n\nIf the random vector X = (X_1, \\cdots, X_n) satisfies the Laplace transform\n\\mathbb{E}[\\exp\\left(-\\langle s, X\\rangle \\right)] = \\frac{1}{|I + R \\operatorname{diag}(s)|^{\\alpha}},\nthen it obeys the \\Gamma(\\alpha, R) distribution.\n\n\n\n\n                  \n                  Example\n                  \n                \n\nIf \\alpha=\\frac{1}{2} and X\\sim \\chi^2_n or X\\sim \\Gamma(\\alpha=\\frac{n}{2}, \\theta=2), then the covariance matrix R = 2I_n and\n\\mathbb{E}[\\exp(-\\langle s, X\\rangle)] = \\prod_{i=1}^n \\mathbb{E}[\\exp(-s_i X_i)] = \\prod_{i=1}^n \\int_0^{\\infty} \\frac{x^{-1/2} e^{-x/2}}{2^{1/2}\\Gamma(\\frac{1}{2})} e^{-s_i x} dx = \\prod_{i=1}^n \\frac{1}{\\sqrt{2s_i + 1}}.\n\n\nNote, not all values of \\alpha suffice to produce an admissible distribution. Some possible values of \\alpha are given in1.\n\n\n                  \n                  Example\n                  \n                \n\nSuppose X_i\\sim \\mathcal{N}(\\mathbf{0}_p, R), then the Wishart matrix S = \\sum_{i=1}^n X_i X_i^T \\sim \\mathcal{W}_p(n, R). The diagonal part of  S is X_i\\odot X_i by Hadamard product. Then, the Laplace transform (or equivalently moment generating function) is\n\\begin{aligned}\n\\mathcal{L}(\\operatorname{diag}(S)) &amp;= \\int dX_1 \\cdots dX_n \\;p(X_1, X_2, \\cdots, X_n) e^{-s^T (\\sum_{i=1}^n X_i\\odot X_i)} \\\\&amp;= \\left[ \\int dX \\frac{1}{\\sqrt{2\\pi}} |R|^{-1/2} \\exp\\left(-\\frac{1}{2} X^T R^{-1} X\\right) \\exp(-s^T (X\\odot X))\\right]^n \\\\\n&amp;= \\left[\\int dX \\frac{1}{\\sqrt{2\\pi}} |R|^{-1/2} \\exp\\left(-\\frac{1}{2} X^T (R^{-1} + 2\\operatorname{diag}(s)) X\\right) \\right]^n\\\\\n&amp;= |R|^{-n/2} |( R^{-1} + 2\\operatorname{diag}(s) )|^{-n/2}\\\\\n&amp;= |I + 2R \\operatorname{diag}(s)|^{-n/2}.\n\\end{aligned}\nTherefore, all 2\\alpha\\in \\mathbb{N} are admissible values.\n\n\nVariational Technique\n\n\nIn order to distinguish the dependence and independence, it is very common to introduce the correlation matrix for the n dimensional vector X, that is, C(\\tau) = [C_{11}, \\tau C_{12}; \\tau C_{21} ,C_{22}] in the spirit of variational method, then the left-hand and right-hand sides of the desired inequality are referring the case \\tau = 1 and \\tau = 0. It equivalently means the function\n\n\n\\tau \\mapsto \\mu(Z_i(\\tau)\\le s_i, i=1,2\\dots, n)\nis non-decreasing in \\tau, where Z_i = \\frac{X_i^2}{2} and s_i = \\frac{t_i^2}{2}. Let f(z,\\tau) be the joint distribution‚Äôs density function of Z(\\tau), then that is to show the derivative \\partial_{\\tau} f(z, \\tau) is non-negative.\n\n\nThe following claim is from Lebesgue‚Äôs dominated convergence theorem. The differentiation can be swapped with the Laplace transform.\n\n\n\\int_{[0, \\infty)^{n}} e^{-\\bf{\\lambda}\\cdot z} \\partial_{\\tau} f(z, \\tau) dz = \\partial_{\\tau} \\int_{[0,\\infty)^{n}} e^{-\\bf{\\lambda}\\cdot z} f(z, \\tau) dz\nwhich equals to\n \\int_{[0,\\infty)^{n}} e^{-\\bf{\\lambda}\\cdot z} f(z, \\tau) dz = \\mathbb{E} \\exp(-\\frac{1}{2}\\sum_{i=1}^n \\lambda_i X_i^2(\\tau)) = |I + \\Lambda C(\\tau)|^{-1/2}.\n\n\nThe rest is a linear algebra problem only. Here \\Lambda is not important anymore, we drop it as identity.\n\n\n \\det (I + C(\\tau)) = \\det(C_{11} + I)\\det(C_{22} + I - \\tau^2(C_{21})(C_{11} + I)^{-1} (C_{21})^T )\nwhich should be decreasing in \\tau.\nIn the original proof by Thomas Royen, the inequality is extended to the distributions such that the Laplace transform is infinitely divisible.\nNotes\n\n\n\nLinks\n\narxiv.org/pdf/1408.1028\n\nFootnotes\n\n\nSchechtman, Gideon, Th Schlumprecht, and Joel Zinn. ‚ÄúOn the Gaussian measure of the intersection.‚Äù Annals of probability (1998): 346-357. ‚Ü© ‚Ü©2\n\n\nKhatri, Chinubhai G. ‚ÄúOn certain inequalities for normal distributions and their applications to simultaneous confidence bounds.‚Äù The Annals of Mathematical Statistics (1967): 1853-1867. ‚Ü©\n\n\n"},"2022-Fall/on-an-application-of-Gr√∂nwall's-inequality":{"title":"on an application of Gr√∂nwall's inequality","links":[],"tags":["math-AP","math-CA"],"content":"Introduction\nWe start with a simple application of Gr√∂nwall‚Äôs inequality.\n\n\n                  \n                  Gr√∂nwall&#039;s inequality \n                  \n                \n\nIf the following relation holds\n0\\le f(x) \\le C \\int_0^x f(s) ds,\\quad x\\in [0, A],\nthen f(x) = 0.\n\n\nThe traditional way (of course a nice one) is letting\nh(x) = e^{-C x} \\int_0^x f(s) ds,\nand utilize the relation\nh&#039;(x) = e^{-C x} \\left(f(x) - C \\int_0^x f(s) ds\\right) \\ge 0.\nHere, we attempt with an alternative way.  We define the integral operator \\mathcal{A}: L^{\\infty}_{+}[0, A]\\mapsto L^{\\infty}_{+}[0, A] by the following:\n\\mathcal{A} f:= C\\int_0^x f(s) ds.\nThen \\mathcal{A} is a positive and compact operator (why?).  According to the Krein-Rutman theorem1, if its spectral radius r(\\mathcal{A}) is a positive eigenvalue, and we must have the corresponding eigenfunction \\phi(x) &gt; 0 strictly positive. However, the definition of \\mathcal{A} implies that \\mathcal{A}\\phi (0) = 0, which gives a contradiction. Therefore, the spectral radius r(\\mathcal{A}) = 0.\nObserve that 0\\le f(x) \\le \\mathcal{A} f(x) implies 0\\le f(x) \\le \\mathcal{A}^n f(x) (why?), the Gelfand‚Äôs formula implies \\|\\mathcal{A}^k\\|_{op}\\to 0 as k\\to\\infty, hence f(x) = 0 by taking n\\to \\infty.\n\nExtension\nIf there is another operator \\mathcal{B} that commutes with \\mathcal A, then the spectral radius r(\\mathcal{A} + \\mathcal{B}) can be estimated. We consider the abstract problem as follows.\n\n\n                  \n                  Extension of Gr√∂nwall&#039;s inequality \n                  \n                \n\nLet  \\mathcal{B} be a linear positive operator with r(B) &lt; 1 that commutes with \\mathcal{A}, and\n0\\le f(x) \\le \\mathcal{A} f + \\mathcal{B} f,\nthen f(x) = 0.\n\n\nThe commutativity implies an estimate r(\\mathcal A + \\mathcal{B}) \\le r(\\mathcal{A}) + r(\\mathcal{B}) &lt; 1 (why?). Then the same argument holds since (\\mathcal{A} + \\mathcal{B})^k\\to 0 as k\\to \\infty.\nThis conclusion seems somewhat trivial.  Let us consider an immediate application in transport equation.\nBackground of transport equation\nThe transport equation describes the dynamics of radiative particles interacting with the environment (absorption, scattering, etc.). For instance, supposing the medium is homogeneous, the governing equation can be written in the following form:\n\\begin{aligned}\nv\\cdot \\nabla u(x, v) + \\sigma_a u &amp;= \\sigma_s (\\mathcal{K} u - u)\\quad\\text{ in } D\\times \\mathbb{S}^{d-1},\\\\\nu|_{\\Gamma_{-}} &amp;= h(x, v),\n\\end{aligned}\nwhere \\mathcal{K} is the scattering operator, which represents the probability of scatter events that change direction v&#039; to the direction v.  The function h(x, v) is the source defined on the incoming boundary set:\n\\Gamma_{-} = \\left\\{(x, v)\\in\\partial D\\times \\mathbb{S}^{d-1}\\mid v\\cdot n(x) &lt; 0 \\right\\}. \nCone-beam source\nThe cone-beam source function means h(x, v) is quite focusing. The precise definition is the following.\n\n\n                  \n                  Cone-beam source \n                  \n                \n\nIf h(x, v) satisfies that\n\nh is non-negative;\nThere exists a set V\\subset \\mathbb{S}^{d-1} that \\operatorname{supp} h\\subset \\partial D \\times V\\cap \\Gamma_{-}.\n\nThen h is called a cone-beam source.\n\n\nIntuitively, this means the source is one-way dominated (like a laser) and only supported on a certain subset of \\Gamma_{-}. In a special case that \\sigma_s = 0, we find the solution can be solved directly.\nu(x, v) = h(x - \\tau_{-}(x, v)v, v) E(x, x - \\tau_{-}(x, v)v), \\quad E(x, x - sv) = \\exp\\left( - \\int_0^s \\sigma_a(x - tv) dt\\right),\nwhere \\tau_{-}(x, v) denotes the distance from x to the boundary following -v direction.\nNonlinearity\nIn a practical scenario, \\sigma_a may depend on the solution‚Äôs flux (e.g., multi-photon absorption), therefore we obtain a nonlinear equation\nu(x, v) = h(x - \\tau_{-}(x, v) v, v) \\exp\\left( - \\int_0^{\\tau_{-}(x, v)} \\sigma_a(x - tv, \\langle u \\rangle ) dt\\right), \\quad \\langle u \\rangle = \\int_{\\mathbb{S}^{d-1}} u(x, v) dv,\nwhere dv represents the usual probability measure on the sphere. Here, we need some continuity assumption.\n\n\n                  \n                  Assumption on Lipschitz continuity \n                  \n                \n\n\\newcommand{\\aver}[1]{\\langle #1 \\rangle}\n|\\sigma_a(x, \\aver{u}) - \\sigma_a(x, \\aver{w})| \\le L |\\aver{u}(x) - \\aver{w}(x)|\n\n\nLet us first assume the existence of the solution and focus on the uniqueness. If there exists a solution w different from u, then we have:\nu - w = h(x-\\tau_{-}(x, v)v, v) \\left[ \\exp\\left(-\\int_0^{\\tau_{-}(x,v)} \\sigma_a(x-tv, \\langle u \\rangle )dt\\right)-  \\exp\\left(-\\int_0^{\\tau_{-}(x,v)} \\sigma_a(x-tv, \\langle w \\rangle )dt\\right)\\right].\n\n\n                  \n                  Lemma \n                  \n                \n\nIf a, b \\ge c \\ge 0, then |e^{-a} - e^{-b}| \\le e^{-c} |a - b|.\n\n\nLet f:= \\langle u - w\\rangle, using this simple lemma, and integrate over \\mathbb{S}^{d-1}, there exists a constant C &gt; 0 that\n|f(x)| \\le \\overline{h}  \\int_{V} \\int_0^{\\tau_{-}(x,v)} |\\sigma_a(x - tv, \\langle u \\rangle) - \\sigma_a(x - tv, \\langle w \\rangle)| dt dv \\le C   \\int_{V} \\int_0^{\\tau_{-}(x,v)} |f(x-tv)| dt dv,\nwhere \\overline{h} = \\sup_{\\Gamma_{-}} h and C is a constant.  This inequality is just an analog of the previous Gr√∂nwall‚Äôs inequality, which has zero spectral radius. Thus, we must have f(x) = 0, which proves the uniqueness.\n\n\n                  \n                  Remark \n                  \n                \n\nThe general uniqueness can be proved in a different flavor, but it requires slightly more restrictive dependence of \\sigma_a on \\langle {u} \\rangle. For scatter-free medium plus a cone-beam source, it only needs Lipschitz continuity.\n\n\nIsotropic Scattering\nOnce the scattering is present, the uniqueness is slightly more challenging (there is an alternative way to prove this), assume that \\sigma_s is a positive constant, then we can represent the solution by (let \\sigma_t := \\sigma_a + \\sigma_s)\n\\begin{aligned}\nu(x, v) = &amp;\\,h(x - \\tau_{-}(x, v) v, v) \\exp\\left( - \\int_0^{\\tau_{-}(x, v)} \\sigma_t(x - tv, \\langle u \\rangle ) dt\\right) \\\\&amp;+ \\int_0^{\\tau_{-}(x, v)} \\exp\\left( - \\int_0^{s} \\sigma_t(x - tv, \\langle u \\rangle ) dt\\right) \\sigma_s \\langle u \\rangle(x-sv) ds.\n\\end{aligned}\nSimilar to the previous derivation, we let f: = \\langle u - w\\rangle, then integrate the above equation over the whole \\mathbb{S}^{d-1}, it shows (using the lemma, polar coordinate transformation, maximum principle)\n\\begin{aligned}\n|f(x)| &amp;\\le C   \\int_{V} \\int_0^{\\tau_{-}(x,v)} |f(x-tv)| dt dv + \\frac{1}{\\nu_{d-1}}\\int_{D} \\frac{e^{-\\sigma_s|x-y|}}{|x - y|^{d-1}} \\sigma_s  |f (y)| dy \\\\&amp;\\qquad+ \\int_{\\mathbb{S}^{d-1}} \\int_0^{\\tau_{-}(x, v)} \\int_0^s e^{-s \\sigma_s}L|f(x - tv)| \\sigma_s \\langle u \\rangle(x-sv) dt ds dv  \\\\\n&amp;\\le C   \\int_{V} \\int_0^{\\tau_{-}(x,v)} |f(x-tv)| dt dv + \\frac{1 + L\\ell \\overline{h}}{\\nu_{d-1}}\\int_{D} \\frac{e^{-\\sigma_s|x-y|}}{|x - y|^{d-1}} \\sigma_s  |f (y)| dy,\n\\end{aligned}\nwhere \\ell = \\operatorname{diam}(D). We make the following observation.\n\n\n                  \n                  Commutativity Lemma \n                  \n                \n\nLet \\mathcal{A} and \\mathcal{S} be L^2(D)\\mapsto L^2(D) operators,\n\\mathcal{A} f:= \\int_{V} \\int_0^{\\tau_{-}(x,v)} |f(x-tv)| dt dv,\\quad S f :=\\displaystyle\\int_{D} \\frac{e^{-\\sigma_s |x - y|}}{|x - y|^{d-1}} f(y) dy.\nThen \\mathcal{A} commutes with \\mathcal{S}.\n\n\nA quick proof for this property. Let f be extended to \\mathbb{R}^d with zero outside D, then we can write\nS \\mathcal{A} f = \\int_{\\mathbb{R}^d} \\int_{V}\\int_0^{\\infty} \\frac{e^{-\\sigma_s |x - y|}}{|x - y|^{d-1}} f(y - sv) ds dv dy,\nand we can derive \\mathcal{A}\\mathcal{S} similarly:\n\\mathcal{A} S f = \\int_{V}\\int_0^{\\infty} \\int_{\\mathbb{R}^d} \\frac{e^{-\\sigma_s|x-sv- y|}}{|x-sv-y|^{d-1}} f(y) dy ds dv = \\int_{V} \\int_0^{\\infty} \\int_{\\mathbb{R}^d} \\frac{e^{-\\sigma_s|x-sv - (y&#039;-sv)|}}{|x - y&#039;|^{d-1}} f(y&#039;-sv) dy&#039; ds dv.\nThat implies the following relation.\n|f(x)| \\le C \\mathcal{A} |f| + \\frac{(1 + L\\ell \\overline{h})}{\\nu_{d-1}} \\sigma_s \\mathcal{S} |f|.\nThen we have the concluding theorem by noticing that \\|\\mathcal{S}\\|_{op} \\le 1 - e^{-\\sigma_s \\ell} (why?).\n\n\n                  \n                  Uniqueness Theorem \n                  \n                \n\nIf (1 + L\\ell \\overline{h}) (1 - e^{-\\sigma_s \\ell}) &lt; 1, then the cone-beam source permits a unique solution (if exists).\n\n\nNotes\n\n\nThis uniqueness result simply serves as an exercise utilizing the Gr√∂nwall‚Äôs inequality. This result is only feasible for weak scattering medium.\n\n\nThe commutativity is necessary to estimate the spectral radius, a slightly more general condition is mentioned in2.\n\n\nFootnotes\n\n\nen.wikipedia.org/wiki/Krein%E2%80%93Rutman_theorem ‚Ü©\n\n\nZima, M. ‚ÄúA theorem on the spectral radius of the sum of two operators and its application.‚Äù Bulletin of the Australian Mathematical Society 48.3 (1993): 427-434. ‚Ü©\n\n\n"},"2025-Summer/on-Hardy-inequalities":{"title":"on Hardy inequalities","links":[],"tags":["math-AP"],"content":"Notes\n\n\n\nLinks\n\n\n"},"2025-Summer/on-Weyl‚Äôs-asymptotic-law":{"title":"on Weyl‚Äôs asymptotic law","links":[],"tags":["math-AP","math-MP"],"content":"Motivation\nIntroduction\nThoughts\nConnections\nNotes\n\n\n\nLinks\n\n\n"},"2025-Summer/on-diffusion-models":{"title":"on diffusion models","links":[],"tags":["math-NA","cs-LG"],"content":"Notes\n\n\n\nLinks\n\n\n"},"2025-Summer/on-interpolation-theorems":{"title":"on interpolation theorems","links":[],"tags":["math-AP"],"content":"Notes\n\n\n\nLinks\n\n\n"},"index":{"title":"Welcome to Latent Seminar","links":[],"tags":[],"content":"\n\n\n                  \n                  Note\n                  \n                \n\nThis seminar series is purely for personal interests.\n\n"},"Untitled":{"title":"Untitled","links":[],"tags":[],"content":""},"on-Sinkhorn's-method":{"title":"on Sinkhorn's method","links":[],"tags":["math-NA"],"content":"Introduction\nSinkhorn‚Äôs Theorem bridges the positive matrices (positive entries) with the doubly stochastic matrices by diagonal multipliers, i.e., there are diagonal matrices D_1 and D_2 that\nD_1 A D_2 e = e, \\quad e^T D_1 A D_2 = e^T\nThe proof can be found in various methods, but most are based on certain kind of fixed-point property. For instance, the geometric proof uses the Brouwer‚Äôs fixed-point theorem. The convergence of the Sinkhorn‚Äôs algorithm seeks for the vectors x and y by iteratively computing\ny_{k+1} = r./(A x_k), \\quad x_{k+1} = c ./ (A^T y_{k+1}) \nwhere r is the row sum vector and c is the column sum vector. They can be merged into one iteration by\nx_{k+1} = T (x_k):= c ./ (A^T (r ./ A x_{k})).\nThe theory uses the nonlinear Perron-Frobenius theorem to find the fixed-point. Clearly, the map T sends the positive cone \\mathbb{R}^{n}_+ to itself, here we need a little bit more compactness to exploit the fixed-point theorem. Either seeking for the boundedness or define \\widehat{T} x = T(x) / \\|T(x)\\|_1, then a fixed-point of \\widehat{T} also works due to invariance of scaling. When the matrix A is relaxed to only nonnegative entries, there are proofs showing if A is fully indecomposable, then the same conclusion holds.\nBy a simple generalization, it is natural to ask for non-singular integral kernel A(x,y) &gt; 0 such that\n\\int_{D_q} p(x) A(x, y) q(y) d y = 1,\\quad \\int_{D_p} p(x) A(x, y) q(y) d x = 1\nThen a natural iteration will be h_{k+1}(y) = T h_k:= \\dfrac{c(y)} { \\displaystyle\\int_{D_q} \\dfrac{ A(x, y) r(x) }{ \\displaystyle\\int_{D_p} A(x,y) h_k(y) dy }dx} \nand we seek for a fixed-point of h = \\widehat{T} h, where \\widehat{T} is a normalization of T, the boundedness of h_k comes at no price, for a certain kind of compactness, we can add the equi-continuity requirement which becomes a smoothness condition on A(x,y) such that A(x, y) is equi-continuous in y, then a convergent subsequence of h_k will be what we need. Therefore A can be also a weakly singular kernel as well.\nIf A(x, y, t) is an evolution of integral operator converges as t\\to\\infty which gradually looses the equi-continuity or boundedness, it is interesting to see whether the corresponding solution h^{\\ast}(y, t) also converges.\nNotes\n\n\n\nLinks\n\n\n"},"on-Sinkhorn's-theorem":{"title":"on Sinkhorn's theorem","links":[],"tags":["math-NA"],"content":"Introduction\nSinkhorn‚Äôs Theorem bridges the positive matrices (positive entries) with the doubly stochastic matrices by diagonal multipliers, i.e., there are diagonal matrices D_1 and D_2 that\nD_1 A D_2 e = e, \\quad e^T D_1 A D_2 = e^T\nThe proof can be found in various methods, but most are based on certain kind of fixed-point property. For instance, the geometric proof uses the Brouwer‚Äôs fixed-point theorem. The convergence of the Sinkhorn‚Äôs algorithm seeks for the vectors x and y by iteratively computing\ny_{k+1} = r./(A x_k), \\quad x_{k+1} = c ./ (A^T y_{k+1}) \nwhere r is the row sum vector and c is the column sum vector. They can be merged into one iteration by\nx_{k+1} = T (x_k):= c ./ (A^T (r ./ A x_{k})).\nThe theory uses the nonlinear Perron-Frobenius theorem to find the fixed-point. Clearly, the map T sends the positive cone \\mathbb{R}^{n}_+ to itself, here we need a little bit more compactness to exploit the fixed-point theorem. Either seeking for the boundedness or define \\widehat{T} x = T(x) / \\|T(x)\\|_1, then a fixed-point of \\widehat{T} also works due to invariance of scaling. When the matrix A is relaxed to only nonnegative entries, there are proofs showing if A is fully indecomposable, then the same conclusion holds.\nBy a simple generalization, it is natural to ask for non-singular integral kernel A(x,y) &gt; 0 such that\n\\int_{D_q} p(x) A(x, y) q(y) d y = 1,\\quad \\int_{D_p} p(x) A(x, y) q(y) d x = 1\nThen a natural iteration will be h_{k+1}(y) = T h_k:= \\dfrac{c(y)} { \\displaystyle\\int_{D_q} \\dfrac{ A(x, y) r(x) }{ \\displaystyle\\int_{D_p} A(x,y) h_k(y) dy }dx} \nand we seek for a fixed-point of h = \\widehat{T} h, where \\widehat{T} is a normalization of T, the boundedness of h_k comes at no price, for a certain kind of compactness, we can add the equi-continuity requirement which becomes a smoothness condition on A(x,y) such that A(x, y) is equi-continuous in y, then a convergent subsequence of h_k will be what we need. Therefore A can be also a weakly singular kernel as well.\nIf A(x, y, t) is an evolution of integral operator converges as t\\to\\infty which gradually looses the equi-continuity or boundedness, it is interesting to see whether the corresponding solution h^{\\ast}(y, t) also converges.\nNotes\n\n\n\nLinks\n\n\n"},"on-Sinkhorn's-Theorem":{"title":"on Sinkhorn's Theorem","links":[],"tags":["math-NA"],"content":"Introduction\nSinkhorn‚Äôs Theorem bridges the positive matrices (positive entries) with the doubly stochastic matrices by diagonal multipliers, i.e., there are diagonal matrices D_1 and D_2 that\nD_1 A D_2 e = e, \\quad e^T D_1 A D_2 = e^T\nThe proof can be found in various methods, but most are based on certain kind of fixed-point property. For instance, the geometric proof uses the Brouwer‚Äôs fixed-point theorem. The convergence of the Sinkhorn‚Äôs algorithm seeks for the vectors x and y by iteratively computing\ny_{k+1} = r./(A x_k), \\quad x_{k+1} = c ./ (A^T y_{k+1}) \nwhere r is the row sum vector and c is the column sum vector. They can be merged into one iteration by\nx_{k+1} = T (x_k):= c ./ (A^T (r ./ A x_{k})).\nThe theory uses the nonlinear Perron-Frobenius theorem to find the fixed-point. Clearly, the map T sends the positive cone \\mathbb{R}^{n}_+ to itself, here we need a little bit more compactness to exploit the fixed-point theorem. Either seeking for the boundedness or define \\widehat{T} x = T(x) / \\|T(x)\\|_1, then a fixed-point of \\widehat{T} also works due to invariance of scaling. When the matrix A is relaxed to only nonnegative entries, there are proofs showing if A is fully indecomposable, then the same conclusion holds.\nBy a simple generalization, it is natural to ask for non-singular integral kernel A(x,y) &gt; 0 such that\n\\int_{D_q} p(x) A(x, y) q(y) d y = 1,\\quad \\int_{D_p} p(x) A(x, y) q(y) d x = 1\nThen a natural iteration will be h_{k+1}(y) = T h_k:= \\dfrac{c(y)} { \\displaystyle\\int_{D_q} \\dfrac{ A(x, y) r(x) }{ \\displaystyle\\int_{D_p} A(x,y) h_k(y) dy }dx} \nand we seek for a fixed-point of h = \\widehat{T} h, where \\widehat{T} is a normalization of T, the boundedness of h_k comes at no price, for a certain kind of compactness, we can add the equi-continuity requirement which becomes a smoothness condition on A(x,y) such that A(x, y) is equi-continuous in y, then a convergent subsequence of h_k will be what we need. Therefore A can be also a weakly singular kernel as well.\nIf A(x, y, t) is an evolution of integral operator converges as t\\to\\infty which gradually looses the equi-continuity or boundedness, it is interesting to see whether the corresponding solution h^{\\ast}(y, t) also converges.\nNotes\n\n\n\nLinks\n\n\n"},"2022-Fall/on-Sinkhorn's-Theorem":{"title":"on Sinkhorn's Theorem","links":[],"tags":["math-NA"],"content":"Background\nSinkhorn‚Äôs Theorem bridges the positive matrices (positive entries) with the doubly stochastic matrices by diagonal multipliers, i.e., there are diagonal matrices D_1 and D_2 that\nD_1 A D_2 e = e, \\quad e^T D_1 A D_2 = e^T\nThe proof can be found in various methods, but most are based on certain kind of fixed-point property. For instance, the geometric proof uses the Brouwer‚Äôs fixed-point theorem. The convergence of the Sinkhorn‚Äôs algorithm seeks for the vectors x and y by iteratively computing\ny_{k+1} = r./(A x_k), \\quad x_{k+1} = c ./ (A^T y_{k+1}) \nwhere r is the row sum vector and c is the column sum vector. They can be merged into one iteration by\nx_{k+1} = T (x_k):= c ./ (A^T (r ./ A x_{k})).\nThe theory uses the nonlinear Perron-Frobenius theorem to find the fixed-point. Clearly, the map T sends the positive cone \\mathbb{R}^{n}_+ to itself, here we need a little bit more compactness to exploit the fixed-point theorem. Either seeking for the boundedness or define \\widehat{T} x = T(x) / \\|T(x)\\|_1, then a fixed-point of \\widehat{T} also works due to invariance of scaling. When the matrix A is relaxed to only nonnegative entries, there are proofs showing if A is fully indecomposable, then the same conclusion holds.\nThoughts\nBy a simple generalization, it is natural to ask for non-singular integral kernel A(x,y) &gt; 0 such that\n\\int_{D_q} p(x) A(x, y) q(y) d y = 1,\\quad \\int_{D_p} p(x) A(x, y) q(y) d x = 1\nThen a natural iteration will be h_{k+1}(y) = T h_k:= \\dfrac{c(y)} { \\displaystyle\\int_{D_q} \\dfrac{ A(x, y) r(x) }{ \\displaystyle\\int_{D_p} A(x,y) h_k(y) dy }dx} \nand we seek for a fixed-point of h = \\widehat{T} h, where \\widehat{T} is a normalization of T, the boundedness of h_k comes at no price, for a certain kind of compactness, we can add the equi-continuity requirement which becomes a smoothness condition on A(x,y) such that A(x, y) is equi-continuous in y, then a convergent subsequence of h_k will be what we need. Therefore A can be also a weakly singular kernel as well.\nIf A(x, y, t) is an evolution of integral operator converges as t\\to\\infty which gradually looses the equi-continuity or boundedness, it is interesting to see whether the corresponding solution h^{\\ast}(y, t) also converges.\nNotes\n\n\n\nLinks\n\n\n"},"on-the-ReLU-two-layer-networks":{"title":"on the ReLU two-layer networks","links":[],"tags":["math-NA","math-CA"],"content":"Introduction\nSpectrum Aspects\nTraining Aspects\nFurther discussion\nNotes\n\n\n\nLinks\n\n\n"},"2022-Fall/on-the-ReLU-two-layer-networks":{"title":"on the ReLU two-layer networks","links":[],"tags":["math-NA","math-CA"],"content":"Introduction\nSpectrum Aspects\nTraining Aspects\nFurther discussion\nNotes\n\n\n\nLinks\n\n\n"}}